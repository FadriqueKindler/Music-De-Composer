{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                        # IMPORT MODULES #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as ms\n",
    "import librosa\n",
    "import librosa.feature\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "from pydub import AudioSegment\n",
    "ms.use(\"seaborn-muted\")\n",
    "%matplotlib inline\n",
    "import soundfile as sf\n",
    "import sys\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, scale\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                            # DEFINING PATHS #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputSong_path = \"../DATA/MusicDemos/\"\n",
    "inputSong_name = \"VULFPECK-Cory_Wong\"\n",
    "input_song = inputSong_path + inputSong_name + \".wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                     # IMPORT AND PLOT SONG FEATURES #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_song(yourSong_path, sr = 44100, n_fft = 1024, hop_length = 512):\n",
    "             \n",
    "# import song #\n",
    "    filename = yourSong_path\n",
    "    y, sr = librosa.load(filename)\n",
    "    \n",
    "# create directory to save all graphs #\n",
    "    dirName = \"../GRAPHS/GRAPHS_FOR_{}\".format(inputSong_name)\n",
    "    \n",
    "    try:\n",
    "# Create target Directory #\n",
    "        os.mkdir(dirName)\n",
    "        print(\"Directory \" , dirName ,  \" Created \") \n",
    "    except FileExistsError:\n",
    "        print(\"Directory \" , dirName ,  \" already exists\")\n",
    "\n",
    "# print song name #\n",
    "    print(\"Your Chosen Song : {}\".format(filename[19:-4]))\n",
    "    \n",
    "# print duration #\n",
    "    duration = librosa.core.get_duration(y=y,sr=sr)\n",
    "    print(\"Duration: \" + str(\"{:0.2f}\".format(duration)) + \" seconds\")\n",
    "    \n",
    "# Get song tempo #\n",
    "    tempo, beats = librosa.beat.beat_track(y=y, sr=sr)\n",
    "    print(\"Song Tempo: \"+ str(\"{:0.2f}\".format(tempo)) + \" BPM\")\n",
    "\n",
    "# Print audio player #\n",
    "    display(ipd.Audio(data = filename, rate =sr))\n",
    "\n",
    "# Display Audio Wave #\n",
    "    plt.figure(figsize=(24,6))\n",
    "\n",
    "    librosa.display.waveplot(y, sr=sr)\n",
    "    plt.title('Mono');\n",
    "    plt.savefig(dirName + '/Audiowave.png'.format(inputSong_name))\n",
    "    \n",
    "# Display HARMONIC + PERCUSSIVE (MONO) #\n",
    "    y_harm, y_perc = librosa.effects.hpss(y)\n",
    "    plt.figure(figsize=(24,6))\n",
    "    librosa.display.waveplot(y_harm, sr=sr, alpha=0.35)\n",
    "    librosa.display.waveplot(y_perc, sr=sr, color='r', alpha=0.25)\n",
    "    plt.title('Harmonic + Percussive')\n",
    "    plt.savefig(dirName + '/Harmonic_Percussive_AudioWave.png'.format(inputSong_name))\n",
    "\n",
    "    \n",
    "# Plot mfcc (normalized) # \n",
    "    mfcc = librosa.feature.mfcc(y = y , n_fft=1024, hop_length=512)\n",
    "    S = librosa.feature.melspectrogram(y = y, sr=sr)\n",
    "    S_dB = librosa.power_to_db(S, ref = np.max)\n",
    "    \n",
    "    plt.figure(figsize=(22, 6))\n",
    "    librosa.display.specshow(S_dB, x_axis='time',\n",
    "                          y_axis='mel', sr=sr,\n",
    "                          fmax=8000)\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Mel-frequency spectrogram')\n",
    "    plt.savefig(dirName + '/Mel-Spectrogram.png'.format(inputSong_name))\n",
    "\n",
    "    \n",
    "    mfcc = librosa.feature.mfcc(S = S_dB, n_mfcc= 15, n_fft=n_fft, hop_length=hop_length)\n",
    "    mfcc_nzd = sklearn.preprocessing.scale(mfcc, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(22, 6))\n",
    "    librosa.display.specshow(mfcc_nzd, sr=sr, x_axis='time');\n",
    "    plt.savefig(dirName + '/MFCC(Normalized).png'.format(inputSong_name))\n",
    "\n",
    "    \n",
    "# Plot Chromagrams #   \n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr, n_chroma=12, n_fft=4096)\n",
    "    chroma_cqt = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
    "    \n",
    "    plt.figure(figsize=(22,6))\n",
    "    librosa.display.specshow(chroma_stft, y_axis='chroma', x_axis='time')\n",
    "    plt.title('chroma_stft')\n",
    "    plt.colorbar()\n",
    "    plt.savefig(dirName + '/Chroma(STFT).png'.format(inputSong_name))\n",
    "\n",
    "    plt.figure(figsize=(22,6))\n",
    "    librosa.display.specshow(chroma_cqt, y_axis='chroma', x_axis='time')\n",
    "    plt.title('chroma_cqt')\n",
    "    plt.colorbar()\n",
    "    plt.savefig(dirName + '/Chroma(CQT).png'.format(inputSong_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_song(input_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                     # CREATE PRIMARY DATAFRAME #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_primaryDf(inputSong_path, sr = 44100, n_fft = 1024, hop_length = 512):\n",
    "    \n",
    "# Define variables # \n",
    "    dictKeySong_ValueArray = {}\n",
    "    s_c = []\n",
    "    s_r = []\n",
    "    s_f = []\n",
    "    rms = []\n",
    "    zcr = []\n",
    "    chgrm = []\n",
    "    mfcc = []\n",
    "    \n",
    "    \n",
    "    y, sr = librosa.load(inputSong_path, sr=sr)\n",
    "    dictKeySong_ValueArray[inputSong_path] = y\n",
    "            \n",
    "    s_c.append(librosa.feature.spectral_centroid(y, sr=sr, n_fft=n_fft, hop_length=hop_length).ravel())\n",
    "    s_r.append(librosa.feature.spectral_rolloff(y, sr=sr, n_fft=n_fft, hop_length=hop_length).ravel())\n",
    "    s_f.append(librosa.onset.onset_strength(y=y, sr=sr).ravel())\n",
    "    rms.append(librosa.feature.rms(y, frame_length=n_fft, hop_length=hop_length).ravel())\n",
    "    zcr.append(librosa.feature.zero_crossing_rate(y, frame_length=n_fft, hop_length=hop_length).ravel())\n",
    "    chgrm.append(librosa.feature.chroma_stft(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length).ravel())\n",
    "\n",
    "# Append MFCC #\n",
    "    mfcc_array = librosa.feature.mfcc(y, n_fft=n_fft, hop_length=hop_length, n_mfcc=15)\n",
    "    mfcc.append(mfcc_array.ravel())\n",
    "        \n",
    "        \n",
    "    primaryDf = pd.DataFrame(list(dictKeySong_ValueArray.items()))\n",
    "    \n",
    "    primaryDf['Spectral_Centroid'] = s_c\n",
    "    primaryDf['Spectral_Rolloff'] = s_r\n",
    "    primaryDf['Spectral_flux'] = s_f\n",
    "    primaryDf['Rms'] = rms\n",
    "    primaryDf['Zcr'] = zcr\n",
    "    primaryDf['Chromagram'] = chgrm\n",
    "    primaryDf[\"Mfcc\"] = mfcc\n",
    "    \n",
    "    primaryDf = primaryDf.rename(columns = {0: \"Song_Name\" , 1: \"Song_Array_values\"})\n",
    "    \n",
    "    primaryDf.set_index('Song_Name')\n",
    "        \n",
    "    return primaryDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primaryDf = create_primaryDf(input_song)\n",
    "primaryDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                      # CREATE FINAL DATAFRAME #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_finalDf(df = primaryDf, sr = 44100 , n_fft = 1024, hop_length = 512):\n",
    "    \n",
    "    mean_lst = []\n",
    "    std_lst = []\n",
    "    kurt_lst = []\n",
    "    skew_lst = []\n",
    "    \n",
    "    useless_cols = [\"Song_Name\", \"Song_Array_values\", \n",
    "                    \"Spectral_Centroid\", \"Spectral_Rolloff\", \n",
    "                    \"Spectral_flux\", \"Rms\", \"Zcr\", \n",
    "                    \"Chromagram\", \"Mfcc\"]\n",
    "    \n",
    "    columns = list(primaryDf)[2:]\n",
    "    \n",
    "# Return columns #\n",
    "    for column in columns:\n",
    "         \n",
    "        data_mean = primaryDf[column].loc[0].mean()\n",
    "        data_std = primaryDf[column].loc[0].std()\n",
    "        data_kurt = kurtosis(primaryDf[column].loc[0])\n",
    "        data_skew = skew(primaryDf[column].loc[0])\n",
    "\n",
    "        primaryDf['{}_Mean'.format(column)] = data_mean\n",
    "        primaryDf['{}_Std'.format(column)] = data_std\n",
    "        primaryDf['{}_Kurt'.format(column)] = data_kurt\n",
    "        primaryDf['{}_Skew'.format(column)] = data_skew\n",
    "\n",
    "    finalDf = primaryDf.drop(columns = useless_cols)\n",
    "\n",
    "    return finalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDf = create_finalDf()\n",
    "finalDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                        # EXPORT SONG AS PICKLE #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_song = input_song[19:-4]\n",
    "exportedSong_pickle = finalDf.to_pickle(\"../DATA/DEMO_SONGS/{}.pkl\".format(exported_song))\n",
    "exported_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                          # DEFINING PATHS #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPickle_path = \"../DATA/DEMO_SONGS/\"\n",
    "\n",
    "TRAIN = \"../DATA/PICKLES/Model_Features_Dataset.pkl\"\n",
    "TEST = inputPickle_path + exported_song + \".pkl\"\n",
    "MODEL = \"../DATA/MODELS/NeuralNetworks_Model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                              # GENRES #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = {0: 'Blues', 1: 'Classical', 2: 'Country', 3: 'Disco', 4: 'Hiphop',\n",
    "          5: 'Jazz', 6: 'Metal', 7: 'Pop', 8: 'Reggae', 9: 'Rock'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                         # LOAD MODEL #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_load(path = MODEL, show=False):\n",
    "\n",
    "    modelo = load_model(path)\n",
    "    if show:\n",
    "        print(modelo.summary())\n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = model_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                               # NORMALIZE TEST DATA FOR PREDICTION #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(path):\n",
    "\n",
    "# Training data #\n",
    "    data = pd.read_pickle(TRAIN)\n",
    "    X = data.drop('Genres', axis=1)\n",
    "    \n",
    "# Test data #\n",
    "    Xt = pd.read_pickle(path)\n",
    "    rows = Xt.shape[0]\n",
    "    \n",
    "# Append original data and test data #\n",
    "    Xt = X.append(Xt, ignore_index=True)\n",
    "    \n",
    "# Normalize #\n",
    "    sc = StandardScaler().fit_transform(Xt.values)\n",
    "    Xt = pd.DataFrame(sc[-rows:], index=Xt[-rows:].index, columns=Xt.columns)\n",
    "    return Xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = normalize(TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                             # PREDICT GENRE #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, Xt):\n",
    "\n",
    "    preds = model.predict_classes(Xt)\n",
    "    predicted = genres.get(preds[0])\n",
    "    probs = model.predict(Xt)[0]\n",
    "    return predicted, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, probs = predict(modelo, Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                         # SHOW PREDICTION RESULTS # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(preds, probs):\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.title(f'Predicted genre: {preds}')\n",
    "    plt.bar(genres.values(), probs, color= \"r\")\n",
    "    for j in range(len(probs)):\n",
    "        plt.text(x=j - 0.1, y=probs[j], s='{:.2f} %'.format((probs[j]) * 100), size=10)\n",
    "    plt.savefig(\"../GRAPHS/GRAPHS_FOR_{}/Predicted_Genre.png\".format(exported_song))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(preds, probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
